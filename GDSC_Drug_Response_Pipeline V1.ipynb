{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a69dbca8",
   "metadata": {},
   "source": [
    "# Drug Response Prediction Using Machine Learning & AI (GDSC)\n",
    "\n",
    "This notebook executes the complete experiment described in your proposal: predict drug response (IC₅₀) for a **single drug** and **single lineage** using **GDSC** open data, with **Linear Regression** and **Random Forest** models.\n",
    "\n",
    "**Pipeline**: Download → Load/Explore → Filter (drug/lineage) → Clean/Scale → Train/Evaluate → Plots → Save artifacts.\n",
    "\n",
    "> Data source: GDSC (CC BY 4.0). See proposal for context and references.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d07e96",
   "metadata": {},
   "source": [
    "## 1) Setup\n",
    "\n",
    "Install required libraries (Colab/local)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3999cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in Colab, uncomment the line below\n",
    "# !pip -q install pandas numpy scikit-learn matplotlib requests openpyxl xlrd\n",
    "\n",
    "import os, io, json, warnings, zipfile, textwrap\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "DATA_DIR = \"gdsc_data\"\n",
    "OUT_DIR = \"outputs\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "URLS = {\n",
    "    \"expression\": \"https://www.cancerrxgene.org/gdsc1000/GDSC1000_WebResources/Home_files/CellLine_RMA_proc_basalExp.txt\",\n",
    "    \"ic50\": \"https://www.cancerrxgene.org/gdsc1000/GDSC1000_WebResources/Home_files/GDSC1_fitted_dose_response_25Feb20.xlsx\",\n",
    "    \"cell_lines\": \"https://www.cancerrxgene.org/gdsc1000/GDSC1000_WebResources/Home_files/Cell_Lines_Details.xlsx\",\n",
    "    \"compounds\": \"https://www.cancerrxgene.org/gdsc1000/GDSC1000_WebResources/Home_files/Screened_Compounds.xlsx\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558f662",
   "metadata": {},
   "source": [
    "## 2) Download data (GDSC)\n",
    "\n",
    "This block downloads the expression matrix (TSV), dose–response (IC₅₀) sheet, cell line metadata, and compound metadata. It is robust to the expression file being plain text (not ZIP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a60c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GDSC datasets...\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://www.cancerrxgene.org/gdsc1000/GDSC1000_WebResources/Home_files/CellLine_RMA_proc_basalExp.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m expr_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCellLine_RMA_proc_basalExp.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(expr_path):\n\u001b[1;32m---> 12\u001b[0m     safe_download(URLS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpression\u001b[39m\u001b[38;5;124m\"\u001b[39m], expr_path)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mic50\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_lines\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompounds\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     14\u001b[0m     p \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_DIR, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m, in \u001b[0;36msafe_download\u001b[1;34m(url, path)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msafe_download\u001b[39m(url, path):\n\u001b[0;32m      4\u001b[0m     r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      7\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(r\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32mE:\\Programs\\Anaconda\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1021\u001b[0m     )\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://www.cancerrxgene.org/gdsc1000/GDSC1000_WebResources/Home_files/CellLine_RMA_proc_basalExp.txt"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def safe_download(url, path):\n",
    "    r = requests.get(url, timeout=120)\n",
    "    r.raise_for_status()\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "print(\"Downloading GDSC datasets...\")\n",
    "expr_path = os.path.join(DATA_DIR, \"CellLine_RMA_proc_basalExp.txt\")\n",
    "if not os.path.exists(expr_path):\n",
    "    safe_download(URLS[\"expression\"], expr_path)\n",
    "for key in [\"ic50\", \"cell_lines\", \"compounds\"]:\n",
    "    p = os.path.join(DATA_DIR, f\"{key}.xlsx\")\n",
    "    if not os.path.exists(p):\n",
    "        safe_download(URLS[key], p)\n",
    "print(\"✅ Download complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a90ef1",
   "metadata": {},
   "source": [
    "## 3) Load and quick sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fe5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = pd.read_csv(os.path.join(DATA_DIR, \"CellLine_RMA_proc_basalExp.txt\"), sep=\"\\t\")\n",
    "ic50 = pd.read_excel(os.path.join(DATA_DIR, \"ic50.xlsx\"))\n",
    "meta = pd.read_excel(os.path.join(DATA_DIR, \"cell_lines.xlsx\"))\n",
    "compounds = pd.read_excel(os.path.join(DATA_DIR, \"compounds.xlsx\"))\n",
    "\n",
    "expr.shape, ic50.shape, meta.shape, compounds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9b5cf",
   "metadata": {},
   "source": [
    "## 4) Choose **drug** and **lineage** (from proposal example)\n",
    "\n",
    "- Drug: *Erlotinib*  \n",
    "- Lineage: *Lung*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c3b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRUG_NAME = \"Erlotinib\"\n",
    "LINEAGE = \"Lung\"\n",
    "DRUG_NAME, LINEAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf63fc1",
   "metadata": {},
   "source": [
    "## 5) Filter & merge\n",
    "\n",
    "- Filter IC₅₀ rows for the selected drug  \n",
    "- Filter metadata rows for the selected lineage  \n",
    "- Merge by `COSMIC_ID`  \n",
    "- Join expression (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16781fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by drug and lineage\n",
    "ic50_sel = ic50[ic50[\"DRUG_NAME\"].str.contains(DRUG_NAME, case=False, na=False)].copy()\n",
    "meta_sel = meta[meta[\"Tissue\"].str.contains(LINEAGE, case=False, na=False)].copy()\n",
    "\n",
    "# Merge dose-response with lineage\n",
    "df = ic50_sel.merge(meta_sel[[\"COSMIC_ID\",\"Tissue\",\"Sample Name\",\"Cancer Type\"]], on=\"COSMIC_ID\", how=\"inner\")\n",
    "\n",
    "# Expression has COSMIC_ID as the first column header; rename to match\n",
    "expr = expr.rename(columns={expr.columns[0]: \"COSMIC_ID\"})\n",
    "expr_sel = expr[expr[\"COSMIC_ID\"].isin(df[\"COSMIC_ID\"])]\n",
    "\n",
    "merged = df.merge(expr_sel, on=\"COSMIC_ID\", how=\"inner\")\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e30668a",
   "metadata": {},
   "source": [
    "### Identify IC₅₀ target column\n",
    "\n",
    "GDSC files vary in the exact column name. We try common options and fall back to log-transform if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible = [c for c in [\"LNIC50\",\"LN_IC50\",\"LOG_IC50\",\"IC50\"] if c in merged.columns]\n",
    "if len(possible)==0 and \"IC50 (uM)\" in merged.columns:\n",
    "    merged[\"LN_IC50\"] = np.log(merged[\"IC50 (uM)\"].clip(lower=1e-12))\n",
    "    target_col = \"LN_IC50\"\n",
    "elif len(possible)>0:\n",
    "    target_col = possible[0]\n",
    "else:\n",
    "    raise ValueError(\"No IC50 column detected; inspect 'merged.columns'.\")\n",
    "\n",
    "target_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ab3b1",
   "metadata": {},
   "source": [
    "### Build feature matrix X and target y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aaf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_feature = {\"COSMIC_ID\",\"Tissue\",\"Sample Name\",\"Cancer Type\",\"DRUG_ID\",\"DRUG_NAME\",\"CELL_LINE_NAME\",\n",
    "               \"SCREENING_SET\",\"DATASET\",\"SANGER_MODEL_ID\",\"GDSC1FIT_ID\", target_col}\n",
    "for c in list(merged.columns):\n",
    "    if \"IC50\" in c and c != target_col:\n",
    "        non_feature.add(c)\n",
    "    if c in [\"AUC\",\"RMSE\",\"EINF\",\"HS\",\"SLOPE\",\"R2\"]:\n",
    "        non_feature.add(c)\n",
    "\n",
    "feature_cols = [c for c in merged.columns if c not in non_feature and merged[c].dtype != \"O\"]\n",
    "\n",
    "# Drop feature columns with too many NaNs (>30%)\n",
    "keep = merged[feature_cols].dropna(axis=1, thresh=int(0.7*len(merged))).columns.tolist()\n",
    "\n",
    "X = merged[keep].copy()\n",
    "y = merged[target_col].astype(float).copy()\n",
    "info = merged[[\"COSMIC_ID\",\"Sample Name\",\"Tissue\",\"DRUG_NAME\"]].copy()\n",
    "\n",
    "X.shape, y.shape, len(keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62047efe",
   "metadata": {},
   "source": [
    "## 6) Preprocess & split\n",
    "\n",
    "- Median-impute missing values  \n",
    "- Standardize features (`StandardScaler`)  \n",
    "- 80/20 train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccca912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median impute\n",
    "for c in X.columns:\n",
    "    if X[c].isna().any():\n",
    "        X[c] = X[c].fillna(X[c].median())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.values)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y.values, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d76c178",
   "metadata": {},
   "source": [
    "## 7) Train models\n",
    "\n",
    "- **Linear Regression**  \n",
    "- **Random Forest Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17487e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = LinearRegression().fit(X_train, y_train)\n",
    "rf = RandomForestRegressor(n_estimators=300, n_jobs=-1, random_state=42).fit(X_train, y_train)\n",
    "lin, rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07724ee3",
   "metadata": {},
   "source": [
    "## 8) Evaluate & visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2e231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, name):\n",
    "    y_pred_tr = model.predict(X_train)\n",
    "    y_pred_te = model.predict(X_test)\n",
    "    rmse_tr = mean_squared_error(y_train, y_pred_tr, squared=False)\n",
    "    rmse_te = mean_squared_error(y_test, y_pred_te, squared=False)\n",
    "    r2_tr = r2_score(y_train, y_pred_tr)\n",
    "    r2_te = r2_score(y_test, y_pred_te)\n",
    "    print(f\"[{name}] RMSE train={rmse_tr:.3f} | test={rmse_te:.3f}  ||  R2 train={r2_tr:.3f} | test={r2_te:.3f}\")\n",
    "    # Plot\n",
    "    plt.figure()\n",
    "    plt.scatter(y_test, y_pred_te, alpha=0.6)\n",
    "    lims = [min(y_test.min(), y_pred_te.min()), max(y_test.max(), y_pred_te.max())]\n",
    "    plt.plot(lims, lims, linestyle='--')\n",
    "    plt.xlabel('Actual (test)'); plt.ylabel('Predicted'); plt.title(f'Predicted vs Actual – {name}')\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    path = os.path.join(OUT_DIR, f'pred_vs_actual_{name.replace(\" \",\"_\").lower()}.png')\n",
    "    plt.savefig(path, bbox_inches='tight'); plt.close()\n",
    "    return {\"model\": name, \"rmse_train\": rmse_tr, \"rmse_test\": rmse_te, \"r2_train\": r2_tr, \"r2_test\": r2_te, \"plot\": path}\n",
    "\n",
    "res_lin = eval_model(lin, \"Linear Regression\")\n",
    "res_rf  = eval_model(rf, \"Random Forest\")\n",
    "\n",
    "res_lin, res_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51770348",
   "metadata": {},
   "source": [
    "### Random Forest: top-20 feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b60d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "order = np.argsort(importances)[::-1][:20]\n",
    "top_feats = [X.columns[i] for i in order]\n",
    "top_vals  = importances[order]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "ypos = np.arange(len(top_feats))[::-1]\n",
    "plt.barh(ypos, top_vals); plt.yticks(ypos, top_feats)\n",
    "plt.title('Top 20 Genes by Importance (RF)'); plt.xlabel('Importance')\n",
    "fi_path = os.path.join(OUT_DIR, 'rf_top_features.png')\n",
    "plt.tight_layout(); plt.savefig(fi_path, bbox_inches='tight'); plt.close()\n",
    "\n",
    "fi_path, list(zip(top_feats, top_vals))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86c9a9d",
   "metadata": {},
   "source": [
    "## 9) Save artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38691bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\"results\":[res_lin, res_rf],\n",
    "           \"feature_importance\":{\"plot\": fi_path, \"top20_genes\": top_feats}}\n",
    "with open(os.path.join(OUT_DIR, \"metrics.json\"), \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "final_df = info.copy()\n",
    "final_df[target_col] = y.values\n",
    "final_df = pd.concat([final_df, pd.DataFrame(X, columns=X.columns)], axis=1)\n",
    "csv_path = os.path.join(OUT_DIR, f\"filtered_{LINEAGE.lower()}_{DRUG_NAME.lower()}_dataset.csv\")\n",
    "final_df.to_csv(csv_path, index=False)\n",
    "\n",
    "sorted(os.listdir(OUT_DIR)), csv_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755d6f03",
   "metadata": {},
   "source": [
    "## 10) Notes & Next steps\n",
    "\n",
    "- Try different drugs or lineages by changing `DRUG_NAME` and `LINEAGE` above.\n",
    "- Add cross-validation and hyperparameter tuning (`GridSearchCV`).\n",
    "- Consider multi-omics features (mutations, CNV, proteomics) to improve signal.\n",
    "- Report can be compiled from `metrics.json` and saved plots.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
